{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "4eOp5WAxClBp"
      },
      "source": [
        ">[Теорема Баєса](#scrollTo=jlG03TFH0Pfl)\n",
        "\n",
        ">[Класифікатор спама](#scrollTo=FEJw5LZz_8vU)\n",
        "\n",
        ">>[Додаткові матеріали](#scrollTo=-a41p9Qpwbny)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Теорема Баєса"
      ],
      "metadata": {
        "id": "jlG03TFH0Pfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Приклад.**\n",
        "Нехай ми маємо тест на деяке захворювання, який має чутливість 99% (імовірність позитивного результату, коли захворювання є). Про захворювання відомо, що воно зустрічається в однієї людини з 10000, тобто ймовірність захворювання — 0.0001.\n",
        "\n",
        "Питання: Яка ймовірність, що особа справді хвора, якщо тест показав позитивний результат?\n",
        "\n",
        "Нехай подія $A$ — пацієнт хворий. Подія  $B$ — отримано позитивний тест. Розглянемо наступні ймовірності.\n",
        "\n",
        "1. $ P(A) $ — апріорна ймовірність бути хворим, тобто $ P(\\text{Хворий}) = 0.0001 $ (апріорна ймовірність наявності захворювання).\n",
        "2. $ P(\\neg A) = 0.9999$ — апріорна ймовірність не хворіти на цю хворобу.\n",
        "2. $ P(B|A) $ — імовірність отримати позитивний результат при хворобі, тобто $ P(\\text{Позитивний тест}|\\text{Хворий}) = 0.99 $.\n",
        "3. $ P(B|\\neg A) $ — імовірність отримати позитивний результат при відсутності хвороби, тобто $ P(\\text{Позитивний тест}|\\text{Відсутність хвороби}) = 1 - 0.99 = 0.01 $.\n",
        "\n",
        "Загальна ймовірність позитивного тесту в даних не наводиться, однак її можна обчислити, користуючись формулою повної ймовірності:\n",
        "\n",
        "$P(B)=P(B|A)\\cdot P(A) + P(B|\\neg A)\\cdot P(\\neg A) = (0.99 \\cdot 0.0001)+(0.01 \\cdot 0.9999) = 0.0101$,\n",
        "\n",
        "отже, маємо розширену формулу Баєса:\n",
        "\n",
        "$\\displaystyle P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B|A)\\cdot P(A) + P(B|\\neg A)\\cdot P(\\neg A)}. $\n",
        "\n",
        "Тепер можна використовувати формулу Баєса для обчислення $ P(\\text{Хворий}|\\text{Позитивний тест}) $:\n",
        "\n",
        "$\\displaystyle P(\\text{Хворий}|\\text{Позитивний тест}) = \\frac{P(\\text{Позитивний тест}|\\text{Хворий}) \\cdot P(\\text{Хворий})}{P(\\text{Позитивний тест})} $\n",
        "\n",
        "$\\displaystyle P(\\text{Хворий}|\\text{Позитивний тест}) = \\frac{0.99 \\cdot 0.0001}{0.0101} = 0.0098 $\n",
        "\n",
        "Отже, апостеріорна ймовірність того, що особа справді хвора при позитивному тесті, складає менше 1%."
      ],
      "metadata": {
        "id": "1cdBi1SU84fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_theorem( p_a, p_b_given_a, p_b_given_not_a ):\n",
        "    \"\"\"\n",
        "    Обчисліть апостеріорну ймовірність за допомогою теореми Баєса.\n",
        "\n",
        "    :param p_a: Попередня ймовірність A\n",
        "    :param p_b_given_a: Імовірність B, якщо A\n",
        "    :param p_b_given_not_a: Імовірність B, якщо не A\n",
        "    : return: обчислена ймовірність\n",
        "    \"\"\"\n",
        "    p_not_a = 1 - p_a\n",
        "    p_b = (p_b_given_a * p_a) + (p_b_given_not_a * p_not_a)\n",
        "    return (p_b_given_a * p_a) / p_b\n",
        "\n",
        "# Присвоєння значень на основі нашої проблеми\n",
        "p_disease = 0.0001\n",
        "p_positive_given_disease = 0.99\n",
        "p_positive_given_no_disease = 0.01\n",
        "\n",
        "# Розрахунок імовірності захворювання при позитивному результаті тесту\n",
        "p_disease_given_positive = bayes_theorem(p_disease, p_positive_given_disease, p_positive_given_no_disease)\n",
        "print(p_disease_given_positive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV6IKe9H0VML",
        "outputId": "ffe95c43-1f66-4b45-86c9-df82e11a0d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00980392156862745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Класифікатор спама"
      ],
      "metadata": {
        "id": "FEJw5LZz_8vU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визначимо деякі навчальні та тестові дані для кожного класу: спаму та важливих повідомлень. Ці повідомлення будуть короткими для стислості та ясності."
      ],
      "metadata": {
        "id": "HNmhuAUmFOl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
        "train_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
        "test_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
      ],
      "metadata": {
        "id": "U_Uch2JuAATD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проводимо ітерацію за розміченими спам-повідомленнями і для кожного слова $w$ у всьому навчальному наборі підраховуємо, скільки спам-повідомлень містить $w$."
      ],
      "metadata": {
        "id": "CCJzKCClFTdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a vocabulary of unique words that occur in known spam emails\n",
        "\n",
        "vocab_words_spam = []\n",
        "\n",
        "for sentence in train_spam:\n",
        "    sentence_as_list = sentence.split()\n",
        "    for word in sentence_as_list:\n",
        "        vocab_words_spam.append(word)\n",
        "\n",
        "print(vocab_words_spam)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_jGcAmmAIRj",
        "outputId": "1e952060-95d2-4720-c065-3d72c924b52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['send', 'us', 'your', 'password', 'review', 'our', 'website', 'send', 'your', 'password', 'send', 'us', 'your', 'account']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перетворюємо кожен елемент списку у множину для виділення унікальних слів — та назад у список."
      ],
      "metadata": {
        "id": "kEw95GL5FY2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_unique_words_spam = list(set(vocab_words_spam))\n",
        "print(vocab_unique_words_spam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VP8tuxSAs0p",
        "outputId": "9df56658-c706-4033-980e-1ec360548708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['website', 'your', 'send', 'password', 'us', 'our', 'account', 'review']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визначаємо ймовірність приналежності кожного слова до спаму та застосовуємо згладжування."
      ],
      "metadata": {
        "id": "4YMt3_GmFcpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_spamicity = {}\n",
        "for w in vocab_unique_words_spam:\n",
        "    emails_with_w = 0     # counter\n",
        "    for sentence in train_spam:\n",
        "        if w in sentence:\n",
        "            emails_with_w+=1\n",
        "\n",
        "    print(f\"Number of spam emails with the word '{w}': {emails_with_w}\")\n",
        "    total_spam = len(train_spam)\n",
        "    spamicity = (emails_with_w+1)/(total_spam+2)\n",
        "    print(f\"Spamicity of the word '{w}': {spamicity} \\n\")\n",
        "    dict_spamicity[w.lower()] = spamicity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu1i7cNZFITA",
        "outputId": "f0448015-c758-46ae-add6-92f40badb823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of spam emails with the word 'website': 1\n",
            "Spamicity of the word 'website': 0.3333333333333333 \n",
            "\n",
            "Number of spam emails with the word 'your': 3\n",
            "Spamicity of the word 'your': 0.6666666666666666 \n",
            "\n",
            "Number of spam emails with the word 'send': 3\n",
            "Spamicity of the word 'send': 0.6666666666666666 \n",
            "\n",
            "Number of spam emails with the word 'password': 2\n",
            "Spamicity of the word 'password': 0.5 \n",
            "\n",
            "Number of spam emails with the word 'us': 2\n",
            "Spamicity of the word 'us': 0.5 \n",
            "\n",
            "Number of spam emails with the word 'our': 4\n",
            "Spamicity of the word 'our': 0.8333333333333334 \n",
            "\n",
            "Number of spam emails with the word 'account': 1\n",
            "Spamicity of the word 'account': 0.3333333333333333 \n",
            "\n",
            "Number of spam emails with the word 'review': 1\n",
            "Spamicity of the word 'review': 0.3333333333333333 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict_spamicity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqfIxltVb5gV",
        "outputId": "b8f0b646-4355-4135-9366-07a46263947d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'website': 0.3333333333333333, 'your': 0.6666666666666666, 'send': 0.6666666666666666, 'password': 0.5, 'us': 0.5, 'our': 0.8333333333333334, 'account': 0.3333333333333333, 'review': 0.3333333333333333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визначаємо ймовірність приналежності кожного слова до важливих повідомлень."
      ],
      "metadata": {
        "id": "VETFyKlaFh2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a vocabulary of unique words that occur in known ham emails\n",
        "vocab_words_ham = []\n",
        "for sentence in train_ham:\n",
        "    sentence_as_list = sentence.split()\n",
        "    for word in sentence_as_list:\n",
        "        vocab_words_ham.append(word)\n",
        "\n",
        "vocab_unique_words_ham = list(set(vocab_words_ham))\n",
        "print(vocab_unique_words_ham)\n",
        "\n",
        "dict_hamicity = {}\n",
        "for w in vocab_unique_words_ham:\n",
        "    emails_with_w = 0     # counter\n",
        "    for sentence in train_ham:\n",
        "        if w in sentence:\n",
        "            print(w+\":\", sentence)\n",
        "            emails_with_w+=1\n",
        "\n",
        "    print(f\"Number of ham emails with the word '{w}': {emails_with_w}\")\n",
        "    total_ham = len(train_ham)\n",
        "    Hamicity = (emails_with_w+1)/(total_ham+2)       # Smoothing applied\n",
        "    print(f\"Hamicity of the word '{w}': {Hamicity} \")\n",
        "    dict_hamicity[w.lower()] = Hamicity\n",
        "                                         # Use built-in lower() to keep all words lower case - useful later when\n",
        "                                         # comparing spamicity vs hamicity of a single word - e.g. 'Your' and\n",
        "                                         # 'your' will be treated as 2 different words if not normalized to lower                                          # case.\n",
        "\n",
        "print(dict_hamicity)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JcBMC5FCcYa",
        "outputId": "ec955d64-e4f8-4e84-bedd-9a238441d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Your', 'benefits', 'report', 'importance', 'activity', 'vows', 'the', 'physical']\n",
            "Your: Your activity report\n",
            "Number of ham emails with the word 'Your': 1\n",
            "Hamicity of the word 'Your': 0.4 \n",
            "benefits: benefits physical activity\n",
            "Number of ham emails with the word 'benefits': 1\n",
            "Hamicity of the word 'benefits': 0.4 \n",
            "report: Your activity report\n",
            "Number of ham emails with the word 'report': 1\n",
            "Hamicity of the word 'report': 0.4 \n",
            "importance: the importance vows\n",
            "Number of ham emails with the word 'importance': 1\n",
            "Hamicity of the word 'importance': 0.4 \n",
            "activity: Your activity report\n",
            "activity: benefits physical activity\n",
            "Number of ham emails with the word 'activity': 2\n",
            "Hamicity of the word 'activity': 0.6 \n",
            "vows: the importance vows\n",
            "Number of ham emails with the word 'vows': 1\n",
            "Hamicity of the word 'vows': 0.4 \n",
            "the: the importance vows\n",
            "Number of ham emails with the word 'the': 1\n",
            "Hamicity of the word 'the': 0.4 \n",
            "physical: benefits physical activity\n",
            "Number of ham emails with the word 'physical': 1\n",
            "Hamicity of the word 'physical': 0.4 \n",
            "{'your': 0.4, 'benefits': 0.4, 'report': 0.4, 'importance': 0.4, 'activity': 0.6, 'vows': 0.4, 'the': 0.4, 'physical': 0.4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обчислюємо ймовірність спаму $P(S)$."
      ],
      "metadata": {
        "id": "HWER4Q4ZChoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_spam = len(train_spam) / (len(train_spam)+(len(train_ham)))\n",
        "print(prob_spam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lPPpc58ClEJ",
        "outputId": "12583861-7428-4fdb-802d-fe50e17f52f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обчислюємо ймовірність важливого повідомлення  $P(H)$."
      ],
      "metadata": {
        "id": "TrsyHi0lCnXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_ham = len(train_ham) / (len(train_spam)+(len(train_ham)))\n",
        "print(prob_ham)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Pw7s3ECo5D",
        "outputId": "a0c0e92e-a167-4b25-cc6f-6d29bbeda5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_ham  + prob_spam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PuRz2VU-gPr",
        "outputId": "7fb21599-ffc8-4e9b-c229-d8119a6dfe1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для повідомлень без розмітки (тестові повідомлення) створюємо список слів."
      ],
      "metadata": {
        "id": "MCDGLfggC2FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = []\n",
        "for i in test_emails['spam']:\n",
        "    tests.append(i)\n",
        "\n",
        "for i in test_emails['ham']:\n",
        "    tests.append(i)\n",
        "\n",
        "print(tests)\n",
        "\n",
        "# split emails into distinct words\n",
        "\n",
        "distinct_words_as_sentences_test = []\n",
        "\n",
        "for sentence in tests:\n",
        "    sentence_as_list = sentence.split()\n",
        "    senten = []\n",
        "    for word in sentence_as_list:\n",
        "        senten.append(word)\n",
        "    distinct_words_as_sentences_test.append(senten)\n",
        "\n",
        "print(distinct_words_as_sentences_test)\n",
        "\n",
        "test_spam_tokenized = [distinct_words_as_sentences_test[0], distinct_words_as_sentences_test[1]]\n",
        "test_ham_tokenized = [distinct_words_as_sentences_test[2], distinct_words_as_sentences_test[3]]\n",
        "print(test_spam_tokenized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM90UJlBC3ik",
        "outputId": "009eef56-a5bc-47c4-aa03-2238f320b72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['renew your password', 'renew your vows', 'benefits of our account', 'the importance of physical activity']\n",
            "[['renew', 'your', 'password'], ['renew', 'your', 'vows'], ['benefits', 'of', 'our', 'account'], ['the', 'importance', 'of', 'physical', 'activity']]\n",
            "[['renew', 'your', 'password'], ['renew', 'your', 'vows']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видаляємо слова, що не зустрічались у навчальному наборі даних."
      ],
      "metadata": {
        "id": "IlJe_GN0DWgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_sentences_spam_test = []\n",
        "for sentence in test_spam_tokenized:\n",
        "    words_ = []\n",
        "    for word in sentence:\n",
        "        if word in vocab_unique_words_spam:\n",
        "            print(f\"'{word}', ok\")\n",
        "            words_.append(word)\n",
        "        elif word in vocab_unique_words_ham:\n",
        "            print(f\"'{word}', ok\")\n",
        "            words_.append(word)\n",
        "        else:\n",
        "            print(f\"'{word}', word not present in labelled spam training data\")\n",
        "    reduced_sentences_spam_test.append(words_)\n",
        "print(reduced_sentences_spam_test)\n",
        "reduced_sentences_ham_test = []                   # repeat for ham words\n",
        "for sentence in test_ham_tokenized:\n",
        "    words_ = []\n",
        "    for word in sentence:\n",
        "        if word in vocab_unique_words_ham:\n",
        "            print(f\"'{word}', ok\")\n",
        "            words_.append(word)\n",
        "        elif word in vocab_unique_words_spam:\n",
        "            print(f\"'{word}', ok\")\n",
        "            words_.append(word)\n",
        "        else:\n",
        "            print(f\"'{word}', word not present in labelled ham training data\")\n",
        "    reduced_sentences_ham_test.append(words_)\n",
        "print(reduced_sentences_ham_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grhctIzoDYot",
        "outputId": "3d164bed-713c-42ec-ff3d-6d772405d458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'renew', word not present in labelled spam training data\n",
            "'your', ok\n",
            "'password', ok\n",
            "'renew', word not present in labelled spam training data\n",
            "'your', ok\n",
            "'vows', ok\n",
            "[['your', 'password'], ['your', 'vows']]\n",
            "'benefits', ok\n",
            "'of', word not present in labelled ham training data\n",
            "'our', ok\n",
            "'account', ok\n",
            "'the', ok\n",
            "'importance', ok\n",
            "'of', word not present in labelled ham training data\n",
            "'physical', ok\n",
            "'activity', ok\n",
            "[['benefits', 'our', 'account'], ['the', 'importance', 'physical', 'activity']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вилучення неключових слів. Це може допомогти класифікатору зосередитись на важливих словах."
      ],
      "metadata": {
        "id": "Qh0IkcvzDdrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_spam_stemmed = []\n",
        "non_key = ['us',  'the', 'of','your']       # non-key words, gathered from spam,ham and test sentences\n",
        "for email in reduced_sentences_spam_test:\n",
        "    email_stemmed=[]\n",
        "    for word in email:\n",
        "        if word in non_key:\n",
        "            print('remove')\n",
        "        else:\n",
        "            email_stemmed.append(word)\n",
        "    test_spam_stemmed.append(email_stemmed)\n",
        "\n",
        "print(test_spam_stemmed)\n",
        "\n",
        "test_ham_stemmed = []\n",
        "non_key = ['us',  'the', 'of', 'your']\n",
        "for email in reduced_sentences_ham_test:\n",
        "    email_stemmed=[]\n",
        "    for word in email:\n",
        "        if word in non_key:\n",
        "            print('remove')\n",
        "        else:\n",
        "            email_stemmed.append(word)\n",
        "    test_ham_stemmed.append(email_stemmed)\n",
        "\n",
        "print(test_ham_stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ihrUr0fDeOn",
        "outputId": "4ec9e1fe-6d47-45bd-9356-fdee1e565fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remove\n",
            "remove\n",
            "[['password'], ['vows']]\n",
            "remove\n",
            "[['benefits', 'our', 'account'], ['importance', 'physical', 'activity']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(reduced_sentences_ham_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xec5fcWCDjdx",
        "outputId": "1f37e549-3719-4705-864a-fac307d46d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Розглянемо приклад реалізації наївного класифікатора Баєса. Його «наївність» полягає в тому, що він не враховує зв’язок одного слова з іншими. Він припускає, що слова, які з’являються в реченні, незалежні одне від одного. Це, звичайно, не так, тому ця рання форма фільтрації спаму була витіснена більш просунутими формами аналізу текстів, такими, які використовують векторизацію слів."
      ],
      "metadata": {
        "id": "OBXKlhsuDps7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mult(list_) :        # function to multiply all word probs together\n",
        "    total_prob = 1\n",
        "    for i in list_:\n",
        "         total_prob = total_prob * i\n",
        "    return total_prob\n",
        "\n",
        "def Bayes(email):\n",
        "    probs_s = []\n",
        "    probs_h = []\n",
        "    for word in email:\n",
        "        Pr_S = prob_spam\n",
        "        # print('prob of spam in general ',Pr_S)\n",
        "        try:\n",
        "            pr_WS = dict_spamicity[word]\n",
        "            # print(f'prob \"{word}\"  is a spam word : {pr_WS}')\n",
        "        except KeyError:\n",
        "            pr_WS = 1/(total_spam+2)  # Apply smoothing for word not seen in spam training data, but seen in ham training\n",
        "            # print(f\"prob '{word}' is a spam word: {pr_WS}\")\n",
        "\n",
        "        Pr_H = prob_ham\n",
        "        # print('prob of ham in general ', Pr_H)\n",
        "        try:\n",
        "            pr_WH = dict_hamicity[word]\n",
        "            # print(f'prob \"{word}\" is a ham word: ',pr_WH)\n",
        "        except KeyError:\n",
        "            pr_WH = (1/(total_ham+2))  # Apply smoothing for word not seen in ham training data, but seen in spam training\n",
        "            # print(f\"WH for {word} is {pr_WH}\")\n",
        "            # print(f\"prob '{word}' is a ham word: {pr_WH}\")\n",
        "\n",
        "        prob_word_is_spam_BAYES = pr_WS\n",
        "        prob_word_is_ham_BAYES = pr_WH\n",
        "\n",
        "\n",
        "        # print('')\n",
        "        # print(f\"Using Bayes, prob the the word '{word}' is spam: {prob_word_is_spam_BAYES}\")\n",
        "        # print('###########################')\n",
        "        probs_s.append(prob_word_is_spam_BAYES)\n",
        "        probs_h.append(prob_word_is_ham_BAYES)\n",
        "    # print(f\"All word probabilities for this sentence: {probs}\")\n",
        "    final_classification = Pr_S*mult(probs_s) /((Pr_S*mult(probs_s))+(Pr_H*mult(probs_h)))\n",
        "    print('###########################')\n",
        "    if final_classification >= 0.5:\n",
        "        print(f'email is SPAM: with spammy confidence of {final_classification*100}%')\n",
        "    else:\n",
        "        print(f'email is HAM: with spammy confidence of {final_classification*100}%')\n",
        "    return final_classification\n"
      ],
      "metadata": {
        "id": "Eov7eVQhDqWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for email in test_spam_stemmed:\n",
        "    print('')\n",
        "    print(f\"           Testing stemmed SPAM email {email} :\")\n",
        "    # print('                 Test word by word: ')\n",
        "    all_word_probs = Bayes(email)\n",
        "    print(all_word_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgijvZb9Dvi0",
        "outputId": "fd15df77-c1e5-4737-b2b4-1cc6222ba6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           Testing stemmed SPAM email ['password'] :\n",
            "###########################\n",
            "email is SPAM: with spammy confidence of 76.92307692307692%\n",
            "0.7692307692307692\n",
            "\n",
            "           Testing stemmed SPAM email ['vows'] :\n",
            "###########################\n",
            "email is HAM: with spammy confidence of 35.714285714285715%\n",
            "0.35714285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for email in test_ham_stemmed:\n",
        "    print('')\n",
        "    print(f\"           Testing stemmed HAM email {email} :\")\n",
        "    print('                 Test word by word: ')\n",
        "    all_word_probs = Bayes(email)\n",
        "    print(all_word_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQHO4Hd7Dz-z",
        "outputId": "dd767b77-b143-4b9a-fabc-d5e7570eaa3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           Testing stemmed HAM email ['benefits', 'our', 'account'] :\n",
            "                 Test word by word: \n",
            "###########################\n",
            "email is SPAM: with spammy confidence of 79.41550190597204%\n",
            "0.7941550190597204\n",
            "\n",
            "           Testing stemmed HAM email ['importance', 'physical', 'activity'] :\n",
            "                 Test word by word: \n",
            "###########################\n",
            "email is HAM: with spammy confidence of 6.041565973900434%\n",
            "0.06041565973900434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Додаткові матеріали\n",
        "\n",
        "\n",
        "1. Implementing a Naive Bayes classifier for text categorization in five steps- https://towardsdatascience.com/implementing-a-naive-bayes-classifier-for-text-categorization-in-five-steps-f9192cdd54c3\n",
        "2. Develop an Intuition for Bayes Theorem With Worked Examples - https://machinelearningmastery.com/intuition-for-bayes-theorem-with-worked-examples/\n",
        "3. How Bayesian inference works - https://e2eml.school/how_bayesian_inference_works\n",
        "4. Bayes’ Theorem Intuition - https://blog.demofox.org/2019/10/25/bayes-theorem-intuition/\n",
        "5. Bayesian Spam Filter Intuition - https://drive.google.com/file/d/1oMS1Cn_mbkMpKrjdfYQppr84GNBb-NDW/view?usp=sharing"
      ],
      "metadata": {
        "id": "-a41p9Qpwbny"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}